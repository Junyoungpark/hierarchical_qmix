diff --git a/src/agent/QmixAgent.py b/src/agent/QmixAgent.py
index 3f8e2fb..6dce25c 100644
--- a/src/agent/QmixAgent.py
+++ b/src/agent/QmixAgent.py
@@ -25,7 +25,7 @@ class QmixAgentConfig(ConfigBase):
         if self.brain.brain['use_noisy_q']:
             self.qnet.qnet.move_module['use_noisy'] = True
             self.qnet.qnet.attack_module['use_noisy'] = True
-            self.qnet['exploration_method'] = 'noisy_net'
+            self.qnet.qnet.qnet['exploration_method'] = 'noisy_net'
         else:
             self.qnet.qnet.move_module['use_noisy'] = False
             self.qnet.qnet.attack_module['use_noisy'] = False
diff --git a/src/brain/QmixBrain.py b/src/brain/QmixBrain.py
index 0ff0244..5401f7c 100644
--- a/src/brain/QmixBrain.py
+++ b/src/brain/QmixBrain.py
@@ -18,9 +18,9 @@ class QmixBrainConfig(ConfigBase):
             'eps_gamma': 0.995,
             'eps_min': 0.01,
             'use_double_q': True,
-            'use_clipped_q': False,
+            'use_clipped_q': True,
             'mixer_use_hidden': True,
-            'use_noisy_q': False
+            'use_noisy_q': True
         }
 
         self.fit = {
diff --git a/src/nn/Linear.py b/src/nn/Linear.py
index c3f7ec5..bee37bd 100644
--- a/src/nn/Linear.py
+++ b/src/nn/Linear.py
@@ -21,8 +21,9 @@ class NoisyLinear(nn.Linear):
         self.reset_parameters()
 
     def reset_parameters(self):
-        torch.nn.init.constant_(self.sigma_weight, self.sigma_init)
-        torch.nn.init.constant_(self.sigma_bias, self.sigma_init)
+        if hasattr(self, 'sigma_weight'):  # Only init after all params added (otherwise super().__init__() fails)
+            torch.nn.init.constant_(self.sigma_weight, self.sigma_init)
+            torch.nn.init.constant_(self.sigma_bias, self.sigma_init)
 
     def forward(self, x):
         return F.linear(x, self.weight + self.sigma_weight * self.epsilon_weight,
diff --git a/src/nn/RelationalGraphLayer.py b/src/nn/RelationalGraphLayer.py
index e46bb06..516d39c 100644
--- a/src/nn/RelationalGraphLayer.py
+++ b/src/nn/RelationalGraphLayer.py
@@ -37,7 +37,7 @@ class RelationalGraphLayer(nn.Module):
 
         self.input_dim = input_node_dim
         self.output_dim = output_node_dim
-        self.init_dim = input_node_dim
+        self.init_dim = init_node_dim
         self.node_types = node_types
         self.edge_types = edge_types
         self.use_residual = use_residual
diff --git a/src/nn/RelationalGraphNetwork.py b/src/nn/RelationalGraphNetwork.py
index 073f4c7..434e332 100644
--- a/src/nn/RelationalGraphNetwork.py
+++ b/src/nn/RelationalGraphNetwork.py
@@ -17,12 +17,12 @@ class RelationalGraphNetworkConfig(ConfigBase):
             'hidden_node_dim': 8,
             'output_node_dim': 16,
             'init_node_dim': 19,
-            'num_hidden_layers': 0,
+            'num_hidden_layers': 2,
             'node_types': [NODE_ALLY, NODE_ENEMY],
             'edge_types': [EDGE_ALLY, EDGE_ENEMY, EDGE_ALLY_TO_ENEMY],
             'updater_conf': MLPConfig().mlp,
             'use_residual': True,
-            'use_concat': False,
+            'use_concat': True,
         }
 
 
diff --git a/src/test/test.py b/src/test/test.py
index c97840a..88ec241 100644
--- a/src/test/test.py
+++ b/src/test/test.py
@@ -16,7 +16,7 @@ if __name__ == '__main__':
         agent.sample_noise()
 
     runner_conf = RunnerConfig(agent=agent)
-    runner_conf.runner['num_runners'] = 2
+    runner_conf.runner['num_runners'] = 1
     runner_conf.runner['n_hist_steps'] = conf.fit['hist_num_time_steps']
     runner = RunnerManager(runner_conf)
 
